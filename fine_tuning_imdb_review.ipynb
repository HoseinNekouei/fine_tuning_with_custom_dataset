{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiiTS7OjrC1Kuq4LgPF2Kl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoseinNekouei/fine_tuning_with_custom_dataset/blob/main/fine_tuning_imdb_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "EQw2NyjwJYR2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7YBDiiuE-Cb"
      },
      "outputs": [],
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the dataset and divide into training and testing set**"
      ],
      "metadata": {
        "id": "gowEYYlAJW3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from posixpath import join\n",
        "from pathlib import Path\n",
        "\n",
        "def read_imdb_split(split_dir):\n",
        "  split_dir= Path(split_dir)\n",
        "  texts=[]\n",
        "  labels=[]\n",
        "\n",
        "  for label_dir in ['neg', 'pos']:\n",
        "    for text_file in (split_dir/label_dir).iterdir():\n",
        "\n",
        "      texts.append(text_file.read_text())\n",
        "      labels.append(0 if label_dir== 'neg' else 1)\n",
        "\n",
        "  return texts, labels\n",
        "\n",
        "train_texts, train_labels= read_imdb_split('/content/aclImdb/train')\n",
        "test_texts, test_labels= read_imdb_split('/content/aclImdb/test')\n",
        "\n",
        "shape=','.join(\n",
        "    [f'train text length: {len(train_texts)}',\n",
        "    f'train labels length: {len(train_labels)}',\n",
        "    f'test text length: {len(test_texts)}',\n",
        "    f'test labels length: {len(test_labels)}'\n",
        "    ])\n",
        "\n",
        "print(shape)"
      ],
      "metadata": {
        "id": "GtvE82NrGAp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_texts, train_labels, test_size= 0.2, stratify= train_labels)\n",
        "\n",
        "length= ','. join([\n",
        "    f'X_train length: {len(X_train)}',\n",
        "    f'X_val length: {len(X_val)}',\n",
        "    f'y_train length: {len(y_train)}',\n",
        "    f'y_val length: {len(y_val)}'\n",
        "])\n",
        "\n",
        "print(length)"
      ],
      "metadata": {
        "id": "uFplsiC2JPHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Tokenizer**"
      ],
      "metadata": {
        "id": "RGCp87YjWcDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "nkF1ZoWnWfHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length= 256)\n",
        "val_encodings= tokenizer(X_val, padding= True, truncation= True, max_length= 256)\n",
        "test_encodings= tokenizer(test_texts, padding= True, truncation= True, max_length= 256)"
      ],
      "metadata": {
        "id": "b4GVdYZyWyJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make Dataset and DataLoader**"
      ],
      "metadata": {
        "id": "6-tDsfgMeR-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "W-SfaC-BeAnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings= encodings\n",
        "    self.labels= labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item= {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "\n",
        "train_set= IMDBDataset(train_encodings, y_train)\n",
        "val_set= IMDBDataset(val_encodings, y_val)\n",
        "test_set= IMDBDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "K-R68eqbc7Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "q1oq-5Wkp9qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "id": "r4DoFS3UqHkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "efN0NPfSm6Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9lXCZ0RoNDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}